<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://adityak2920.github.io/aiblog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://adityak2920.github.io/aiblog/" rel="alternate" type="text/html" /><updated>2020-04-06T15:42:10-05:00</updated><id>https://adityak2920.github.io/aiblog/feed.xml</id><title type="html">Aditya Kumar</title><subtitle>A site for blogging.</subtitle><entry><title type="html">Faster RCNN</title><link href="https://adityak2920.github.io/aiblog/object%20detection/vision/2020/03/18/FasterRCNN.html" rel="alternate" type="text/html" title="Faster RCNN" /><published>2020-03-18T00:00:00-05:00</published><updated>2020-03-18T00:00:00-05:00</updated><id>https://adityak2920.github.io/aiblog/object%20detection/vision/2020/03/18/FasterRCNN</id><content type="html" xml:base="https://adityak2920.github.io/aiblog/object%20detection/vision/2020/03/18/FasterRCNN.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-18-FasterRCNN.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;Introduction&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Object detection is one of the areas of computer vision that is maturing very rapidly. In the last few years we have seen a lot of new Object Detection Algorithms. There are mainly two types of Object Detection Algorithms:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Two Stage Detector: In two stage detectors, we have a region proposal network for localization and then classification head for classifying the localized object. Here the accuracies are high as compared to one stage detectors but speed is quite slow.&lt;/li&gt;
&lt;li&gt;One Stage Detector: In one stage detectors, we have a fully convolutional neural network doing localization and classfication.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Work-in-Progress&quot;&gt;Work in Progress&lt;a class=&quot;anchor-link&quot; href=&quot;#Work-in-Progress&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Aditya Kumar</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://adityak2920.github.io/aiblog/images/FasterRCNN.jpg" /><media:content medium="image" url="https://adityak2920.github.io/aiblog/images/FasterRCNN.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Self Supervised Learning</title><link href="https://adityak2920.github.io/aiblog/self-supervised/vision/2020/02/26/SSL.html" rel="alternate" type="text/html" title="Self Supervised Learning" /><published>2020-02-26T00:00:00-06:00</published><updated>2020-02-26T00:00:00-06:00</updated><id>https://adityak2920.github.io/aiblog/self-supervised/vision/2020/02/26/SSL</id><content type="html" xml:base="https://adityak2920.github.io/aiblog/self-supervised/vision/2020/02/26/SSL.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-26-SSL.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;What-is-Self-Supervised-Learning-?&quot;&gt;What is Self Supervised Learning ?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-is-Self-Supervised-Learning-?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Self Supervised Learning(SSL) is a method to train neural networks in which we don't require any extra labels, we take labels from the input data itself. It's not a very new concept, we are using SSL in NLP from quite some time to train language models, in which we train our model to predict next word of a sentence given a word. It's proved to give accuracies a large boost in NLP tasks beacuse it's observed that a model which learns the nature or the way to generate nature language, can be fine tuned for any task.&lt;/p&gt;
&lt;h2 id=&quot;SSL-in-Computer-Vision&quot;&gt;SSL in Computer Vision&lt;a class=&quot;anchor-link&quot; href=&quot;#SSL-in-Computer-Vision&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In computer vision, it's not being used frequently beacuse we became satisfied or dependent on Imagenet pretrained weights and nowadays also on COCO for detection and segmentation tasks. But in medical domain, these weights don't proved to be very ground breaking, it improved results a little bit but not to a large margin and the same time in these domains, there is not much data available right now. So, for these SSL proved to be a very good option.&lt;/p&gt;
&lt;p&gt;In SSL, there are mainly two types of tasks:-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pretext Tasks: The tasks which we use for pretraining our network are pretext tasks.&lt;/li&gt;
&lt;li&gt;Downstream Tasks: The tasks which we use for fine-tuning our network are downstream tasks.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The pretext tasks can be &lt;a href=&quot;https://arxiv.org/abs/1603.08511&quot;&gt;Colorization&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1604.07379&quot;&gt;Inpainting&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1603.09246&quot;&gt;Placing image pathches in the right place&lt;/a&gt;, &lt;a href=&quot;https://zpascal.net/cvpr2018/Jenni_Self-Supervised_Feature_Learning_CVPR_2018_paper.pdf&quot;&gt;Classify Corrupted Images&lt;/a&gt;, etc.&lt;/p&gt;
&lt;p&gt;One thing we should be taken into account is that the pretext task should be choosen such that it should give an understanding of data and so that it makes easier to solve downstream task. It's suggested that we should not be spending too much time in deciding pretext task, we should build an easy and fast task. After that spending time in finetuning through downstream task to check whether it's working or not.&lt;/p&gt;
&lt;h2 id=&quot;Unsupervised-Data-Augmentation-and-Consistency-Loss&quot;&gt;Unsupervised Data Augmentation and Consistency Loss&lt;a class=&quot;anchor-link&quot; href=&quot;#Unsupervised-Data-Augmentation-and-Consistency-Loss&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In July 2019 a paper from google came to show, how we can use data augmentation on unlabeled data to improve accuracy. 
   Now, In this paper they proposed a method for training called Unsupervised Data Augmentation. In this method they are using
&lt;img src=&quot;https://raw.githubusercontent.com/adityak2920/aiblog/master/images/USDA.png&quot; alt=&quot;&quot; title=&quot;Unsupervised Data Augmentation&quot; /&gt;
both labelled and unlabelled data for training with a loss function combining both the loss functions from data. One loss function function is computed from labelled data by supervised learning methods and the other loss is computed from consistency training by enforcing a model to predict similar predictions from augmented and unaugmented unlabelled data. The same model is used for computing both the loss function. The loss which we are getting from unlablled data is called Consistency Loss or Noise Contrastive Estimation. From statistical point, it is basically distance between two prediction distribution. The pretext tasks messes with data in different ways through augmentation but we always want that the prediction with original and messed should be same and the intermediate representation should also be consistent, otherwise it will affect our predictions. At final, we add both the loss functions to train beacuse it penalizes our model for getting different prediction for differnt version of the same data.&lt;/p&gt;
&lt;h2 id=&quot;Credits&quot;&gt;Credits&lt;a class=&quot;anchor-link&quot; href=&quot;#Credits&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I wrote this blog after reading Jeremy Howard blog on Self Supervised learning just to improve my writing skills and to learn concepts in a better fashion.&lt;/p&gt;
&lt;p&gt;Links:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.fast.ai/2020/01/13/self_supervised/&quot;&gt;Jeremy Howard Blog&lt;/a&gt;                                                   &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ai.googleblog.com/2019/07/advancing-semi-supervised-learning-with.html&quot;&gt;Unsupervised Data Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Aditya Kumar</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://adityak2920.github.io/aiblog/images/ssl.png" /><media:content medium="image" url="https://adityak2920.github.io/aiblog/images/ssl.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>